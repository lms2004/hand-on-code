import torch

# ğŸ§  ç”¨äºé¢„è®¡ç®— RoPE é¢‘ç‡ï¼šğœƒâ½â±â¾ = 1 / Î¸^(i / d), æ„é€ æ—‹è½¬ç›¸ä½å› å­ e^{jÎ¸}
def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):
    """
    ğŸ§® é¢„è®¡ç®—æ—‹è½¬é¢‘ç‡çš„å¤æ•°è¡¨ç¤º
    ğŸ“ è¾“å‡ºå½¢çŠ¶: (end, dim // 2)ï¼Œå¤æ•°å€¼ e^{jÏ‰t}
    """

    # ğŸ”¢ æ„é€ é¢‘ç‡å°ºåº¦: ğœ”â‚– = 1 / Î¸^(k/d)ï¼Œå…¶ä¸­ k = 0, 2, ..., dim-2ï¼ˆå–ä¸€åŠé¢‘ç‡ï¼‰
    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))

    # ğŸ•’ ç”Ÿæˆæ—¶é—´æ­¥åºåˆ—: t = [0, 1, 2, ..., end-1]
    t = torch.arange(end, device=freqs.device, dtype=torch.float32)

    # ğŸ” å¤–ç§¯å¾—åˆ°æ‰€æœ‰æ—¶é—´ä¸é¢‘ç‡ç»„åˆ: táµ¢ Ã— ğœ”â±¼ï¼Œå¯¹åº”æ¯ä¸ªä½ç½®å’Œé¢‘ç‡çš„æ—‹è½¬è§’åº¦ Î¸áµ¢â±¼
    freqs = torch.outer(t, freqs)  # shape: (end, dim//2)

    # ğŸ”„ è½¬æ¢ä¸ºå¤æ•° e^{jÎ¸} = cosÎ¸ + jsinÎ¸ï¼Œæ¨¡é•¿ä¸º1ï¼Œæè§’ä¸ºé¢‘ç‡Ã—ä½ç½®
    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # ğŸ“Œ complex64
    return freqs_cis

# ğŸ›ï¸ ä¸ºäº†å¹¿æ’­ï¼Œå°† freq_cis reshape æˆä¸ xq/xk å¯å¯¹é½çš„å½¢çŠ¶
def reshape_for_broadcast(freqs_cis, x):
    """
    ğŸ§© è°ƒæ•´é¢‘ç‡çŸ©é˜µ freqs_cis çš„å½¢çŠ¶ï¼Œä½¿å…¶å¯å¹¿æ’­åˆ° x çš„ shape
    ğŸ’¡ å®é™…æ˜¯å°† (seq_len, head_dim//2) â†’ (1, seq_len, 1, head_dim//2)
    """
    ndim = x.ndim
    assert 0 <= 1 < ndim
    assert freqs_cis.shape == (x.shape[1], x.shape[-1])  # (seq_len, head_dim//2)

    # ğŸ§± æ„é€ å¹¿æ’­å½¢çŠ¶ï¼šåœ¨é™¤ seq_len å’Œ dim å¤–æ’å…¥ 1
    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]
    return freqs_cis.view(*shape)

# âœ¨ ä½ç½®ç¼–ç æ ¸å¿ƒï¼šå°†æ—‹è½¬é¢‘ç‡ freqs_cis åº”ç”¨äº Qã€K å‘é‡
def apply_rotary_emb(xq, xk, freqs_cis):
    """
    ğŸ“ è¾“å…¥ï¼š
        xq, xk: [batch, seq_len, n_heads, head_dim]
        freqs_cis: [seq_len, head_dim // 2] (å¤æ•°æ—‹è½¬å› å­)
    ğŸ“¤ è¾“å‡ºï¼š
        åº”ç”¨æ—‹è½¬åçš„ xq, xkï¼Œshape ç›¸åŒ
    """

    # ğŸ§Š å…ˆå°†æœ€åçš„ head_dim è§†ä½œå¤æ•°ï¼šå®+è™šï¼Œå˜ä¸º [*, head_dim//2] å¤æ•°
    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))
    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))

    # ğŸ§© è°ƒæ•´é¢‘ç‡å½¢çŠ¶ä»¥æ”¯æŒå¹¿æ’­ï¼šä» [seq_len, dim//2] â†’ [1, seq_len, 1, dim//2]
    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)

    # ğŸ’« å¤æ•°ä¹˜æ³•ï¼šç›¸å½“äºå¹³é¢æ—‹è½¬æ“ä½œ (cosÎ¸ + jsinÎ¸)ï¼Œå°†ä½ç½®ä¿¡æ¯ç¼–ç å…¥å‘é‡
    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)  # â†©ï¸ è½¬å›å®æ•°å‘é‡
    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)

    # ğŸ” è¿”å›åŸå§‹ç±»å‹ï¼ˆfloat16/float32ï¼‰ï¼Œä¿æŒå’Œè¾“å…¥ä¸€è‡´
    return xq_out.type_as(xq), xk_out.type_as(xk)

def main():
    # ğŸ§¾ æ¨¡æ‹Ÿå‚æ•°é…ç½®
    batch_size = 2
    seq_len = 4
    n_heads = 2
    head_dim = 8  # å¿…é¡»æ˜¯å¶æ•°ï¼ˆæ‰èƒ½è¢«è½¬æ¢ä¸ºå¤æ•°ï¼‰

    # ğŸŒŸ æ„é€ æ¨¡æ‹Ÿçš„ Qã€K å‘é‡ï¼ˆå¯ä»¥è§†ä½œ transformer attention çš„è¾“å…¥ï¼‰
    xq = torch.randn(batch_size, seq_len, n_heads, head_dim)
    xk = torch.randn(batch_size, seq_len, n_heads, head_dim)

    # ğŸ“ é¢„è®¡ç®— RoPE æ—‹è½¬é¢‘ç‡ e^{jÎ¸}
    freqs_cis = precompute_freqs_cis(head_dim, seq_len)

    # ğŸŒ€ åº”ç”¨æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰
    xq_rot, xk_rot = apply_rotary_emb(xq, xk, freqs_cis)

    # ğŸ“Š æ‰“å°è¾“å‡ºå¯¹æ¯”ï¼ˆä»…å±•ç¤ºå‰å‡ ä¸ªå…ƒç´ ï¼‰
    print("Original Q (before RoPE):\n", xq[0, 0])
    print("\nRotated Q (after RoPE):\n", xq_rot[0, 0])
    print("\nOriginal K (before RoPE):\n", xk[0, 0])
    print("\nRotated K (after RoPE):\n", xk_rot[0, 0])

if __name__ == "__main__":
    main()